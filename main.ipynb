{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from scrap_search import *\n",
    "from scraping_reviews import *\n",
    "\n",
    "# This is a draft of what is still needed it should be checked and fixed\n",
    "# try to set sleep time for 7 days to run the scraper automatically and check the new results\n",
    "\n",
    "# try to call the function from the scrape-search.py file to fetch the asin and pass it through a loop to the scrap review function\n",
    "time = 7 * 24 * 60 * 60 # 7 days in seconds\n",
    "for i in range(10):\n",
    "    with open(f\"query_results_{i}.json\", \"r\") as query_file:\n",
    "        search_results = json.load(query_file) # todo check here\n",
    "    for item in search_results:\n",
    "        asin = search_results[\"asin\"]\n",
    "        reviews = asyncio.run(get_review_details(asin))\n",
    "    with open(f\"query_results_{i+1}.json\", \"w\") as review_file:\n",
    "        json.dump(reviews, review_file) # todo check the writing process"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
